"""
Braille Bottleneck + Semantic Braiding â€” The Science Layer

Architecture:
  Encoder:  â„Â¹Â² â†’ â„Â¹Â² (learned projection)
  Quantizer: â„Â¹Â² â†’ {0,1}^N (deterministic braille lattice, STE for gradients)
  Decoder:  {0,1}^N â†’ â„Â¹Â² (reconstructed belief vector)
  Classifier: {0,1}^N â†’ deity label (downstream task)

Semantic Braiding:
  Multiple encoder variants â†’ shared quantizer â†’ bitwise consensus â†’ single decoder
  z* = majority(zÂ¹, zÂ², ..., záµ) or z* = ðŸ™[Î£ Î±â±¼ zâ±¼ > Ï„]

Five experiments:
  A) Centroid preservation: displacement before/after bottleneck
  B) Task invariance: deity classification, syncretism proximity
  C) Capacity stress test: 72-bit vs 48-bit vs 24-bit phase transition
  D) Semantic braiding: multi-encoder consensus through shared bottleneck
  E) Channel invariance: sensory restriction through braille projection

Runs on Modal with GPU.
"""

import modal
import json
import os

app = modal.App("braille-bottleneck")

image = (
    modal.Image.debian_slim(python_version="3.11")
    .pip_install(
        "torch",
        "numpy",
        "scikit-learn",
        "scipy",
    )
)

# â”€â”€â”€ Constants â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

AXES = [
    "authority", "transcendence", "care", "justice", "wisdom", "power",
    "fertility", "war", "death", "creation", "nature", "order"
]

POLARITY_PAIRS = {
    "authority": "care", "care": "authority",
    "transcendence": "nature", "nature": "transcendence",
    "justice": "fertility", "fertility": "justice",
    "wisdom": "war", "war": "wisdom",
    "power": "death", "death": "power",
    "creation": "order", "order": "creation",
}

DEITY_PRIORS = {
    "Zeus":    [0.9, 0.7, 0.3, 0.6, 0.4, 0.95, 0.3, 0.5, 0.2, 0.4, 0.6, 0.7],
    "Yahweh":  [0.95, 0.95, 0.7, 0.9, 0.8, 0.9, 0.2, 0.3, 0.3, 0.9, 0.3, 0.9],
    "Vishnu":  [0.6, 0.9, 0.9, 0.7, 0.8, 0.7, 0.5, 0.2, 0.3, 0.8, 0.7, 0.8],
    "Odin":    [0.7, 0.5, 0.2, 0.4, 0.95, 0.6, 0.1, 0.8, 0.7, 0.5, 0.4, 0.3],
    "Isis":    [0.4, 0.6, 0.95, 0.5, 0.7, 0.5, 0.9, 0.1, 0.4, 0.6, 0.8, 0.5],
    "Mars":    [0.6, 0.2, 0.1, 0.3, 0.2, 0.8, 0.3, 0.95, 0.6, 0.1, 0.3, 0.4],
    "Ra":      [0.85, 0.8, 0.5, 0.7, 0.6, 0.85, 0.4, 0.3, 0.2, 0.8, 0.5, 0.8],
    "Kali":    [0.5, 0.7, 0.3, 0.6, 0.4, 0.7, 0.3, 0.6, 0.9, 0.5, 0.4, 0.3],
    "Thor":    [0.5, 0.3, 0.4, 0.5, 0.3, 0.85, 0.4, 0.9, 0.3, 0.2, 0.6, 0.4],
    "Athena":  [0.6, 0.5, 0.5, 0.8, 0.9, 0.5, 0.2, 0.6, 0.2, 0.4, 0.3, 0.7],
    "Gaia":    [0.2, 0.4, 0.8, 0.3, 0.4, 0.3, 0.9, 0.1, 0.3, 0.7, 0.95, 0.4],
    "Anubis":  [0.5, 0.6, 0.3, 0.7, 0.5, 0.4, 0.1, 0.2, 0.95, 0.3, 0.2, 0.6],
    "Apollo":  [0.5, 0.6, 0.4, 0.5, 0.85, 0.4, 0.3, 0.2, 0.2, 0.5, 0.5, 0.7],
    "Shiva":   [0.6, 0.9, 0.3, 0.5, 0.7, 0.8, 0.3, 0.4, 0.8, 0.7, 0.5, 0.4],
    "Freya":   [0.3, 0.4, 0.7, 0.3, 0.5, 0.4, 0.85, 0.3, 0.3, 0.4, 0.6, 0.3],
    "Ares":    [0.5, 0.2, 0.1, 0.2, 0.2, 0.7, 0.2, 0.95, 0.5, 0.1, 0.2, 0.3],
}


# â”€â”€â”€ Modal Function â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@app.function(
    image=image,
    gpu="T4",
    timeout=1800,
)
def run_bottleneck_experiment():
    import torch
    import torch.nn as nn
    import torch.optim as optim
    import numpy as np
    from sklearn.metrics import accuracy_score
    import math

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Device: {device}")

    # â”€â”€â”€ Data Generation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def normalize(v):
        n = math.sqrt(sum(x * x for x in v)) or 1
        return [x / n for x in v]

    # Generate training data: noisy samples around each deity prior
    NUM_SAMPLES_PER_DEITY = 500
    NOISE_STD = 0.08

    all_vectors = []
    all_labels = []
    deity_names = list(DEITY_PRIORS.keys())

    for label_idx, (name, prior) in enumerate(DEITY_PRIORS.items()):
        prior_norm = normalize(prior)
        for _ in range(NUM_SAMPLES_PER_DEITY):
            noisy = [p + np.random.normal(0, NOISE_STD) for p in prior_norm]
            noisy = [max(0, min(1, x)) for x in noisy]
            noisy = normalize(noisy)
            all_vectors.append(noisy)
            all_labels.append(label_idx)

    all_vectors = np.array(all_vectors, dtype=np.float32)
    all_labels = np.array(all_labels, dtype=np.int64)

    # Shuffle and split
    indices = np.random.permutation(len(all_vectors))
    split = int(0.8 * len(indices))
    train_idx, test_idx = indices[:split], indices[split:]

    X_train = torch.tensor(all_vectors[train_idx]).to(device)
    y_train = torch.tensor(all_labels[train_idx]).to(device)
    X_test = torch.tensor(all_vectors[test_idx]).to(device)
    y_test = torch.tensor(all_labels[test_idx]).to(device)

    num_deities = len(deity_names)
    print(f"Training samples: {len(X_train)}, Test samples: {len(X_test)}")
    print(f"Deities: {num_deities}")

    # â”€â”€â”€ Braille Bottleneck Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    class BrailleBottleneckModel(nn.Module):
        """
        Full architecture with temperature-annealed quantization:
          Encoder: â„Â¹Â² â†’ â„^N (learned projection to logit space)
          Quantizer: sigmoid(logits * Ï„) â†’ {0,1}^N as Ï„â†’âˆž (STE in forward)
          Decoder: {0,1}^N â†’ â„Â¹Â² (reconstructed vector)
          Classifier: {0,1}^N â†’ deity label (downstream task)

        Key insight: the projection to bit-logits is LEARNED, so gradients
        flow through the linear layers even though the rounding is hard.
        Temperature Ï„ anneals from 1â†’10 during training to sharpen.
        """
        def __init__(self, input_dim=12, bits_per_axis=6, num_classes=16):
            super().__init__()
            self.input_dim = input_dim
            self.bits_per_axis = bits_per_axis
            total_bits = input_dim * bits_per_axis
            self.total_bits = total_bits

            # Encoder: input â†’ bit logits
            self.encoder = nn.Sequential(
                nn.Linear(input_dim, 128),
                nn.ReLU(),
                nn.BatchNorm1d(128),
                nn.Linear(128, 64),
                nn.ReLU(),
                nn.Linear(64, total_bits),  # output: one logit per bit
            )

            # Decoder: bits â†’ reconstructed vector
            self.decoder = nn.Sequential(
                nn.Linear(total_bits, 64),
                nn.ReLU(),
                nn.Linear(64, 128),
                nn.ReLU(),
                nn.Linear(128, input_dim),
            )

            # Classifier: bits â†’ deity label
            self.classifier = nn.Sequential(
                nn.Linear(total_bits, 64),
                nn.ReLU(),
                nn.Dropout(0.2),
                nn.Linear(64, num_classes),
            )

            self.temperature = 1.0

        def quantize(self, logits):
            """
            Differentiable quantization with STE.
            Forward: hard binary. Backward: gradients through sigmoid.
            """
            soft = torch.sigmoid(logits * self.temperature)
            hard = (soft > 0.5).float()
            # STE: hard in forward, soft gradients in backward
            return hard - soft.detach() + soft

        def forward(self, x):
            logits = self.encoder(x)
            bits = self.quantize(logits)
            soft_bits = torch.sigmoid(logits * self.temperature)
            reconstructed = self.decoder(bits)
            class_logits = self.classifier(bits)

            return {
                "bits": bits,
                "soft_bits": soft_bits,
                "logits_raw": logits,
                "reconstructed": reconstructed,
                "logits": class_logits,
            }

    # â”€â”€â”€ Training Loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def train_model(bits_per_axis, epochs=200, lr=1e-3):
        model = BrailleBottleneckModel(
            input_dim=12,
            bits_per_axis=bits_per_axis,
            num_classes=num_deities,
        ).to(device)

        optimizer = optim.Adam(model.parameters(), lr=lr)
        recon_criterion = nn.MSELoss()
        class_criterion = nn.CrossEntropyLoss()

        total_bits = 12 * bits_per_axis
        print(f"\n{'='*50}")
        print(f"Training with {bits_per_axis} bits/axis = {total_bits} total bits")
        print(f"{'='*50}")

        best_test_acc = 0
        history = {"train_loss": [], "test_acc": [], "recon_error": []}

        for epoch in range(epochs):
            model.train()

            # Anneal temperature: 1 â†’ 10 over training
            model.temperature = 1.0 + 9.0 * (epoch / max(epochs - 1, 1))

            # Mini-batch training
            perm = torch.randperm(len(X_train))
            batch_size = 256
            epoch_loss = 0
            n_batches = 0

            for i in range(0, len(X_train), batch_size):
                idx = perm[i:i+batch_size]
                xb = X_train[idx]
                yb = y_train[idx]

                out = model(xb)

                # Reconstruction loss
                loss_recon = recon_criterion(out["reconstructed"], xb)

                # Classification loss
                loss_class = class_criterion(out["logits"], yb)

                # Binarization pressure: push soft bits toward 0 or 1
                soft = out["soft_bits"]
                loss_binary = -torch.mean(soft * torch.log(soft + 1e-8) +
                                          (1 - soft) * torch.log(1 - soft + 1e-8))

                # Total loss
                loss = loss_recon + 0.5 * loss_class + 0.1 * loss_binary

                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

                epoch_loss += loss.item()
                n_batches += 1

            # Evaluate (with hard quantization)
            model.eval()
            model.temperature = 10.0  # hard for eval
            with torch.no_grad():
                out_test = model(X_test)
                preds = out_test["logits"].argmax(dim=1)
                test_acc = (preds == y_test).float().mean().item()
                recon_err = recon_criterion(out_test["reconstructed"], X_test).item()

            history["train_loss"].append(epoch_loss / n_batches)
            history["test_acc"].append(test_acc)
            history["recon_error"].append(recon_err)

            if test_acc > best_test_acc:
                best_test_acc = test_acc

            if (epoch + 1) % 50 == 0 or epoch == 0:
                print(f"  Epoch {epoch+1:3d}: loss={epoch_loss/n_batches:.4f}, "
                      f"acc={test_acc:.4f}, recon={recon_err:.6f}, Ï„={model.temperature:.1f}")

        return model, history, best_test_acc

    # â”€â”€â”€ Experiment A: Centroid Preservation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def experiment_centroid_preservation(model):
        """Measure centroid displacement through the bottleneck."""
        model.eval()
        results = {}

        with torch.no_grad():
            for name, prior in DEITY_PRIORS.items():
                prior_norm = normalize(prior)
                x = torch.tensor([prior_norm], dtype=torch.float32).to(device)

                out = model(x)
                reconstructed = out["reconstructed"][0].cpu().numpy()
                original = np.array(prior_norm)

                # Cosine similarity
                cos_sim = np.dot(original, reconstructed) / (
                    np.linalg.norm(original) * np.linalg.norm(reconstructed) + 1e-8
                )

                # L2 displacement
                l2_dist = np.linalg.norm(original - reconstructed)

                # Bits
                bits = out["bits"][0].cpu().numpy()

                results[name] = {
                    "cosine_similarity": float(cos_sim),
                    "l2_displacement": float(l2_dist),
                    "bits_active": int(bits.sum()),
                    "total_bits": len(bits),
                }

        # Inter-deity distances for comparison
        deity_vecs = [normalize(v) for v in DEITY_PRIORS.values()]
        inter_distances = []
        for i in range(len(deity_vecs)):
            for j in range(i+1, len(deity_vecs)):
                d = np.linalg.norm(np.array(deity_vecs[i]) - np.array(deity_vecs[j]))
                inter_distances.append(d)

        mean_inter = float(np.mean(inter_distances))
        mean_displacement = float(np.mean([r["l2_displacement"] for r in results.values()]))

        results["_summary"] = {
            "mean_cosine_similarity": float(np.mean([r["cosine_similarity"] for r in results.values() if isinstance(r, dict) and "cosine_similarity" in r])),
            "mean_l2_displacement": mean_displacement,
            "mean_inter_deity_distance": mean_inter,
            "displacement_ratio": mean_displacement / mean_inter if mean_inter > 0 else 0,
        }

        return results

    # â”€â”€â”€ Experiment B: Task Invariance â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def experiment_task_invariance(model):
        """Test downstream tasks through the bottleneck."""
        model.eval()

        with torch.no_grad():
            out = model(X_test)
            preds = out["logits"].argmax(dim=1).cpu().numpy()
            true = y_test.cpu().numpy()

        # Overall accuracy
        overall_acc = accuracy_score(true, preds)

        # Per-deity accuracy
        per_deity = {}
        for i, name in enumerate(deity_names):
            mask = true == i
            if mask.sum() > 0:
                per_deity[name] = float(accuracy_score(true[mask], preds[mask]))

        # Syncretism proximity test: are similar deities still similar after bottleneck?
        deity_centroids_original = {}
        deity_centroids_reconstructed = {}

        with torch.no_grad():
            for name, prior in DEITY_PRIORS.items():
                prior_norm = normalize(prior)
                x = torch.tensor([prior_norm], dtype=torch.float32).to(device)
                out = model(x)
                deity_centroids_original[name] = np.array(prior_norm)
                deity_centroids_reconstructed[name] = out["reconstructed"][0].cpu().numpy()

        # Check if pairwise similarity ordering is preserved
        names = list(DEITY_PRIORS.keys())
        original_sims = []
        reconstructed_sims = []
        for i in range(len(names)):
            for j in range(i+1, len(names)):
                o_sim = float(np.dot(deity_centroids_original[names[i]], deity_centroids_original[names[j]]) /
                    (np.linalg.norm(deity_centroids_original[names[i]]) * np.linalg.norm(deity_centroids_original[names[j]]) + 1e-8))
                r_sim = float(np.dot(deity_centroids_reconstructed[names[i]], deity_centroids_reconstructed[names[j]]) /
                    (np.linalg.norm(deity_centroids_reconstructed[names[i]]) * np.linalg.norm(deity_centroids_reconstructed[names[j]]) + 1e-8))
                original_sims.append(o_sim)
                reconstructed_sims.append(r_sim)

        # Rank correlation (Spearman)
        from scipy.stats import spearmanr
        rank_corr, rank_p = spearmanr(original_sims, reconstructed_sims)

        return {
            "classification_accuracy": overall_acc,
            "per_deity_accuracy": per_deity,
            "similarity_rank_correlation": float(rank_corr),
            "similarity_rank_p_value": float(rank_p),
            "n_test_samples": len(true),
        }

    # â”€â”€â”€ Experiment C: Capacity Stress Test â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    print("\n" + "=" * 60)
    print("BRAILLE BOTTLENECK EXPERIMENT")
    print("Encoder â†’ {0,1}^N â†’ Decoder")
    print("=" * 60)

    capacity_results = {}
    bits_configs = [1, 2, 3, 4, 6, 8]  # bits per axis â†’ 12, 24, 36, 48, 72, 96 total

    for bpa in bits_configs:
        total = 12 * bpa
        model, history, best_acc = train_model(bpa, epochs=200)

        # Run experiments
        centroid_res = experiment_centroid_preservation(model)
        task_res = experiment_task_invariance(model)

        capacity_results[total] = {
            "bits_per_axis": bpa,
            "total_bits": total,
            "best_classification_accuracy": best_acc,
            "final_classification_accuracy": task_res["classification_accuracy"],
            "mean_cosine_similarity": centroid_res["_summary"]["mean_cosine_similarity"],
            "mean_l2_displacement": centroid_res["_summary"]["mean_l2_displacement"],
            "displacement_ratio": centroid_res["_summary"]["displacement_ratio"],
            "similarity_rank_correlation": task_res["similarity_rank_correlation"],
            "training_history": {
                "final_loss": history["train_loss"][-1],
                "final_recon_error": history["recon_error"][-1],
            },
        }

        print(f"\n  {total}-bit results:")
        print(f"    Classification: {task_res['classification_accuracy']:.4f}")
        print(f"    Cosine sim: {centroid_res['_summary']['mean_cosine_similarity']:.4f}")
        print(f"    Displacement ratio: {centroid_res['_summary']['displacement_ratio']:.4f}")
        print(f"    Rank correlation: {task_res['similarity_rank_correlation']:.4f}")

    # â”€â”€â”€ Detailed results for 72-bit (the paper's claim) â”€â”€â”€â”€â”€â”€â”€â”€â”€

    print("\n" + "=" * 60)
    print("DETAILED 72-BIT RESULTS (Paper's claim)")
    print("=" * 60)

    model_72, history_72, _ = train_model(6, epochs=300)
    centroid_72 = experiment_centroid_preservation(model_72)
    task_72 = experiment_task_invariance(model_72)

    print("\nCentroid preservation (72-bit):")
    for name in deity_names:
        if name in centroid_72:
            r = centroid_72[name]
            print(f"  {name:12s}: cos_sim={r['cosine_similarity']:.4f}, "
                  f"L2={r['l2_displacement']:.4f}, bits_active={r['bits_active']}/{r['total_bits']}")

    print(f"\n  Mean displacement ratio: {centroid_72['_summary']['displacement_ratio']:.4f}")
    print(f"  (displacement / inter-deity distance â€” lower is better)")

    print(f"\nTask invariance (72-bit):")
    print(f"  Classification accuracy: {task_72['classification_accuracy']:.4f}")
    print(f"  Similarity rank correlation: {task_72['similarity_rank_correlation']:.4f}")
    print(f"  Rank correlation p-value: {task_72['similarity_rank_p_value']:.2e}")

    # â”€â”€â”€ Channel Invariance (sensory restriction) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    print("\n" + "=" * 60)
    print("CHANNEL INVARIANCE EXPERIMENT")
    print("=" * 60)

    channel_results = []
    restriction_configs = [
        ("visual_embodied", [4, 5, 6, 7]),      # fertility, war, death, nature â†’ indices
        ("abstract_conceptual", [1, 9]),          # transcendence, creation
        ("social_political", [0, 3, 5, 11]),      # authority, justice, power, order
    ]

    model_72.eval()
    with torch.no_grad():
        for restriction_name, zero_indices in restriction_configs:
            for deity_name, prior in DEITY_PRIORS.items():
                prior_norm = normalize(prior)

                # Full vector
                x_full = torch.tensor([prior_norm], dtype=torch.float32).to(device)
                out_full = model_72(x_full)

                # Restricted vector (zero out axes)
                restricted = list(prior_norm)
                for idx in zero_indices:
                    restricted[idx] = 0.0
                r_norm = math.sqrt(sum(v*v for v in restricted)) or 1
                restricted = [v / r_norm for v in restricted]
                x_restricted = torch.tensor([restricted], dtype=torch.float32).to(device)
                out_restricted = model_72(x_restricted)

                # Compare bits
                bits_full = out_full["bits"][0].cpu().numpy()
                bits_restricted = out_restricted["bits"][0].cpu().numpy()
                hamming = int(np.sum(bits_full != bits_restricted))

                # Compare reconstructed centroids
                recon_full = out_full["reconstructed"][0].cpu().numpy()
                recon_restricted = out_restricted["reconstructed"][0].cpu().numpy()
                cos_sim = float(np.dot(recon_full, recon_restricted) / (
                    np.linalg.norm(recon_full) * np.linalg.norm(recon_restricted) + 1e-8))

                # Compare classifications
                pred_full = out_full["logits"].argmax(dim=1).item()
                pred_restricted = out_restricted["logits"].argmax(dim=1).item()

                channel_results.append({
                    "deity": deity_name,
                    "restriction": restriction_name,
                    "restricted_axes": [AXES[i] for i in zero_indices],
                    "hamming_distance": hamming,
                    "total_bits": len(bits_full),
                    "braille_identical": hamming == 0,
                    "reconstructed_cosine_sim": cos_sim,
                    "same_classification": pred_full == pred_restricted,
                    "pred_full": deity_names[pred_full],
                    "pred_restricted": deity_names[pred_restricted],
                })

    # Summarize channel invariance
    for restriction_name, _, in restriction_configs:
        subset = [c for c in channel_results if c["restriction"] == restriction_name]
        avg_hamming = np.mean([c["hamming_distance"] for c in subset])
        identical = sum(1 for c in subset if c["braille_identical"])
        avg_cos = np.mean([c["reconstructed_cosine_sim"] for c in subset])
        same_class = sum(1 for c in subset if c["same_classification"])
        print(f"\n  Restriction: {restriction_name}")
        print(f"    Mean Hamming distance: {avg_hamming:.1f}/{subset[0]['total_bits']}")
        print(f"    Braille-identical: {identical}/{len(subset)}")
        print(f"    Mean reconstructed cosine sim: {avg_cos:.4f}")
        print(f"    Same classification: {same_class}/{len(subset)}")

    # â”€â”€â”€ Experiment D: Semantic Braiding â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    print("\n" + "=" * 60)
    print("SEMANTIC BRAIDING EXPERIMENT")
    print("Multiple encoders â†’ shared bottleneck â†’ bitwise consensus")
    print("=" * 60)

    # Train K=5 encoder variants with different initializations
    # and different noise profiles (simulating heterogeneous models)
    K = 5
    braid_models = []
    for k in range(K):
        print(f"\n  Training braid encoder {k+1}/{K}...")
        # Different noise and dropout for each "model"
        torch.manual_seed(42 + k * 1000)
        np.random.seed(42 + k * 1000)

        # Regenerate training data with different noise for each model
        vecs_k = []
        labs_k = []
        noise_std_k = 0.05 + k * 0.02  # increasing noise per model
        for label_idx, (name, prior) in enumerate(DEITY_PRIORS.items()):
            prior_norm = normalize(prior)
            for _ in range(NUM_SAMPLES_PER_DEITY):
                noisy = [p + np.random.normal(0, noise_std_k) for p in prior_norm]
                noisy = [max(0, min(1, x)) for x in noisy]
                noisy = normalize(noisy)
                vecs_k.append(noisy)
                labs_k.append(label_idx)

        vecs_k = np.array(vecs_k, dtype=np.float32)
        labs_k = np.array(labs_k, dtype=np.int64)
        idx_k = np.random.permutation(len(vecs_k))
        split_k = int(0.8 * len(idx_k))

        # Temporarily replace training data
        X_train_k = torch.tensor(vecs_k[idx_k[:split_k]]).to(device)
        y_train_k = torch.tensor(labs_k[idx_k[:split_k]]).to(device)

        # Save originals
        X_train_orig, y_train_orig = X_train, y_train
        X_train, y_train = X_train_k, y_train_k

        model_k, _, acc_k = train_model(6, epochs=150)
        braid_models.append(model_k)
        print(f"    Model {k+1} accuracy: {acc_k:.4f}")

        # Restore
        X_train, y_train = X_train_orig, y_train_orig

    # Now braid: for each deity, get bits from all K models, compute consensus
    braid_results = {"per_deity": {}, "summary": {}}

    with torch.no_grad():
        all_individual_accs = []
        all_braid_accs = []
        all_braid_cos_sims = []

        for deity_name, prior in DEITY_PRIORS.items():
            prior_norm = normalize(prior)
            x = torch.tensor([prior_norm], dtype=torch.float32).to(device)
            original = np.array(prior_norm)

            # Get bits from each model
            all_bits = []
            individual_preds = []
            individual_recons = []
            for model_k in braid_models:
                model_k.eval()
                out_k = model_k(x)
                bits_k = out_k["bits"][0].cpu().numpy()
                all_bits.append(bits_k)
                individual_preds.append(out_k["logits"].argmax(dim=1).item())
                individual_recons.append(out_k["reconstructed"][0].cpu().numpy())

            all_bits = np.array(all_bits)  # (K, 72)

            # Option A: Majority lattice (unweighted)
            majority_bits = (all_bits.mean(axis=0) > 0.5).astype(np.float32)
            majority_bits_tensor = torch.tensor(majority_bits).unsqueeze(0).to(device)

            # Option B: Weighted braid (equal weights for now)
            weights = np.ones(K) / K
            weighted_sum = np.sum(all_bits * weights[:, None], axis=0)
            weighted_bits = (weighted_sum > 0.5).astype(np.float32)

            # Decode the braided bits using the first model's decoder
            # (shared decoder architecture â€” all models have same decoder structure)
            braided_recon = braid_models[0].decoder(majority_bits_tensor)[0].cpu().numpy()
            braided_logits = braid_models[0].classifier(majority_bits_tensor)
            braided_pred = braided_logits.argmax(dim=1).item()

            # Measure agreement between individual models
            bit_agreement = np.mean([
                np.mean(all_bits[i] == all_bits[j])
                for i in range(K) for j in range(i+1, K)
            ])

            # Hamming distance between individual bits and braided bits
            individual_to_braid_hamming = [
                int(np.sum(all_bits[i] != majority_bits))
                for i in range(K)
            ]

            # Cosine similarity of braided reconstruction to original
            braid_cos = float(np.dot(original, braided_recon) / (
                np.linalg.norm(original) * np.linalg.norm(braided_recon) + 1e-8))

            # Individual cosine similarities
            individual_cos = [
                float(np.dot(original, r) / (np.linalg.norm(original) * np.linalg.norm(r) + 1e-8))
                for r in individual_recons
            ]

            braid_results["per_deity"][deity_name] = {
                "bit_agreement_rate": float(bit_agreement),
                "braided_cosine_sim": braid_cos,
                "individual_cosine_sims": individual_cos,
                "mean_individual_cosine": float(np.mean(individual_cos)),
                "braid_improvement": braid_cos - float(np.mean(individual_cos)),
                "braided_pred": deity_names[braided_pred],
                "individual_preds": [deity_names[p] for p in individual_preds],
                "pred_agreement": len(set(individual_preds)) == 1,
                "braid_correct": deity_names[braided_pred] == deity_name,
                "individual_to_braid_hamming": individual_to_braid_hamming,
            }

            all_braid_cos_sims.append(braid_cos)

        # Summary
        per_deity = braid_results["per_deity"]
        braid_results["summary"] = {
            "num_models": K,
            "mean_bit_agreement": float(np.mean([v["bit_agreement_rate"] for v in per_deity.values()])),
            "mean_braided_cosine_sim": float(np.mean(all_braid_cos_sims)),
            "mean_individual_cosine_sim": float(np.mean([v["mean_individual_cosine"] for v in per_deity.values()])),
            "mean_braid_improvement": float(np.mean([v["braid_improvement"] for v in per_deity.values()])),
            "braid_correct_rate": float(np.mean([v["braid_correct"] for v in per_deity.values()])),
            "individual_agreement_rate": float(np.mean([v["pred_agreement"] for v in per_deity.values()])),
        }

        print(f"\n  Braiding summary ({K} models):")
        print(f"    Mean bit agreement: {braid_results['summary']['mean_bit_agreement']:.4f}")
        print(f"    Mean braided cosine sim: {braid_results['summary']['mean_braided_cosine_sim']:.4f}")
        print(f"    Mean individual cosine sim: {braid_results['summary']['mean_individual_cosine_sim']:.4f}")
        print(f"    Braid improvement: {braid_results['summary']['mean_braid_improvement']:+.4f}")
        print(f"    Braid correct rate: {braid_results['summary']['braid_correct_rate']:.4f}")

    # â”€â”€â”€ Compile Final Results â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    final_results = {
        "capacity_stress_test": capacity_results,
        "centroid_preservation_72bit": {
            k: v for k, v in centroid_72.items()
        },
        "task_invariance_72bit": task_72,
        "channel_invariance": channel_results,
        "semantic_braiding": braid_results,
        "summary": {
            "claim": (
                "Emergent theological structuresâ€”defined as population-level centroid "
                "attractors in a designed belief spaceâ€”remain stable when forced through "
                "a fixed, 72-bit discrete bottleneck. This suggests that such structures "
                "are not artifacts of high-dimensional continuous embeddings, but persist "
                "under severe semantic compression."
            ),
            "braiding_claim": (
                "We introduce semantic braiding: a method for fusing heterogeneous models "
                "by projecting their internal states through a shared discrete bottleneck "
                "and combining them at the level of compressed semantic invariants. Unlike "
                "logit- or token-level ensembles, braiding preserves only structure that "
                "survives severe information constraints."
            ),
            "architecture": "Encoder(â„Â¹Â²) â†’ BrailleQuantizer({0,1}â·Â²) â†’ Decoder(â„Â¹Â²)",
            "bottleneck_type": "deterministic quantization with straight-through estimator",
            "bits_per_axis": 6,
            "total_bits": 72,
            "encoding": "2 polarity + 2 intensity + 2 rigidity per axis",
            "braiding": "majority lattice over K=5 encoder variants",
        },
    }

    # Print capacity stress test summary
    print("\n" + "=" * 60)
    print("CAPACITY STRESS TEST SUMMARY")
    print("=" * 60)
    print(f"{'Bits':>6} | {'Accuracy':>10} | {'Cos Sim':>10} | {'Disp Ratio':>12} | {'Rank Corr':>10}")
    print("-" * 60)
    for total_bits in sorted(capacity_results.keys()):
        r = capacity_results[total_bits]
        print(f"{total_bits:>6} | {r['final_classification_accuracy']:>10.4f} | "
              f"{r['mean_cosine_similarity']:>10.4f} | "
              f"{r['displacement_ratio']:>12.4f} | "
              f"{r['similarity_rank_correlation']:>10.4f}")

    return final_results


# â”€â”€â”€ Local entrypoint â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@app.local_entrypoint()
def main():
    print("Launching braille bottleneck experiment on Modal...")
    results = run_bottleneck_experiment.remote()

    # Save results locally
    output_path = "/Users/ryanbarrett/gods-as-centroids/mlx-pipeline/experiment_results.json"
    with open(output_path, "w") as f:
        json.dump(results, f, indent=2, default=str)
    print(f"\nResults saved to {output_path}")

    # Generate markdown report
    report_path = "/Users/ryanbarrett/gods-as-centroids/mlx-pipeline/experiment_results.md"
    generate_markdown_report(results, report_path)


def generate_markdown_report(results, output_path):
    """Generate publishable markdown report from experiment results."""
    lines = [
        "# Braille Bottleneck Experiment â€” Quantitative Results",
        "",
        "## Claim",
        "",
        f"> {results['summary']['claim']}",
        "",
        f"**Architecture:** `{results['summary']['architecture']}`",
        f"**Bottleneck:** {results['summary']['total_bits']} bits "
        f"({results['summary']['bits_per_axis']} per axis Ã— 12 axes)",
        f"**Encoding:** {results['summary']['encoding']}",
        "",
        "---",
        "",
        "## Experiment A: Centroid Preservation (72-bit)",
        "",
        "Does the centroid survive passage through the braille lattice?",
        "",
        "| Deity | Cosine Sim | L2 Displacement | Active Bits |",
        "|-------|-----------|-----------------|-------------|",
    ]

    centroid_data = results["centroid_preservation_72bit"]
    for name in DEITY_PRIORS.keys():
        if name in centroid_data and isinstance(centroid_data[name], dict) and "cosine_similarity" in centroid_data[name]:
            r = centroid_data[name]
            lines.append(f"| {name} | {r['cosine_similarity']:.4f} | {r['l2_displacement']:.4f} | {r['bits_active']}/{r['total_bits']} |")

    if "_summary" in centroid_data:
        s = centroid_data["_summary"]
        lines.extend([
            "",
            f"**Mean cosine similarity:** {s['mean_cosine_similarity']:.4f}",
            f"**Mean L2 displacement:** {s['mean_l2_displacement']:.4f}",
            f"**Mean inter-deity distance:** {s['mean_inter_deity_distance']:.4f}",
            f"**Displacement ratio:** {s['displacement_ratio']:.4f} "
            "(displacement / inter-deity distance â€” lower means centroids are preserved)",
        ])

    lines.extend([
        "",
        "---",
        "",
        "## Experiment B: Task Invariance (72-bit)",
        "",
    ])

    task = results["task_invariance_72bit"]
    lines.extend([
        f"**Classification accuracy:** {task['classification_accuracy']:.4f}",
        f"**Similarity rank correlation (Spearman):** {task['similarity_rank_correlation']:.4f} "
        f"(p = {task['similarity_rank_p_value']:.2e})",
        "",
    ])

    lines.extend([
        "---",
        "",
        "## Experiment C: Capacity Stress Test",
        "",
        "Phase transition in representational capacity:",
        "",
        "| Total Bits | Bits/Axis | Classification | Cosine Sim | Displacement Ratio | Rank Correlation |",
        "|-----------|-----------|---------------|-----------|-------------------|-----------------|",
    ])

    for total_bits in sorted(results["capacity_stress_test"].keys(), key=int):
        r = results["capacity_stress_test"][total_bits]
        lines.append(
            f"| {r['total_bits']} | {r['bits_per_axis']} | "
            f"{r['final_classification_accuracy']:.4f} | "
            f"{r['mean_cosine_similarity']:.4f} | "
            f"{r['displacement_ratio']:.4f} | "
            f"{r['similarity_rank_correlation']:.4f} |"
        )

    lines.extend([
        "",
        "---",
        "",
        "## Channel Invariance",
        "",
    ])

    # Summarize by restriction type
    channel = results["channel_invariance"]
    restriction_types = set(c["restriction"] for c in channel)
    for rtype in sorted(restriction_types):
        subset = [c for c in channel if c["restriction"] == rtype]
        avg_hamming = sum(c["hamming_distance"] for c in subset) / len(subset)
        identical = sum(1 for c in subset if c["braille_identical"])
        avg_cos = sum(c["reconstructed_cosine_sim"] for c in subset) / len(subset)
        same_class = sum(1 for c in subset if c["same_classification"])
        lines.extend([
            f"### {rtype}",
            f"- **Restricted axes:** {', '.join(subset[0]['restricted_axes'])}",
            f"- **Mean Hamming distance:** {avg_hamming:.1f}/72",
            f"- **Braille-identical centroids:** {identical}/{len(subset)}",
            f"- **Mean reconstructed cosine sim:** {avg_cos:.4f}",
            f"- **Same classification:** {same_class}/{len(subset)}",
            "",
        ])

    # Semantic braiding
    if "semantic_braiding" in results:
        braid = results["semantic_braiding"]
        lines.extend([
            "---",
            "",
            "## Experiment D: Semantic Braiding",
            "",
            "Multiple encoder variants â†’ shared braille bottleneck â†’ bitwise majority consensus.",
            "",
            f"**Models braided:** {braid['summary']['num_models']}",
            f"**Mean bit agreement between models:** {braid['summary']['mean_bit_agreement']:.4f}",
            f"**Mean braided cosine similarity:** {braid['summary']['mean_braided_cosine_sim']:.4f}",
            f"**Mean individual cosine similarity:** {braid['summary']['mean_individual_cosine_sim']:.4f}",
            f"**Braid improvement over individual:** {braid['summary']['mean_braid_improvement']:+.4f}",
            f"**Braid correct classification rate:** {braid['summary']['braid_correct_rate']:.4f}",
            "",
            "| Deity | Braided Cos | Mean Indiv Cos | Improvement | Braid Correct | Models Agree |",
            "|-------|-----------|---------------|------------|--------------|-------------|",
        ])
        for name, v in braid["per_deity"].items():
            lines.append(
                f"| {name} | {v['braided_cosine_sim']:.4f} | {v['mean_individual_cosine']:.4f} | "
                f"{v['braid_improvement']:+.4f} | {'âœ“' if v['braid_correct'] else 'âœ—'} | "
                f"{'âœ“' if v['pred_agreement'] else 'âœ—'} |"
            )
        lines.append("")

    lines.extend([
        "---",
        "",
        "*Generated by the Braille Bottleneck + Semantic Braiding Pipeline â€” Gods as Centroids*",
    ])

    report = "\n".join(lines)
    with open(output_path, "w") as f:
        f.write(report)
    print(f"Report written to {output_path}")
