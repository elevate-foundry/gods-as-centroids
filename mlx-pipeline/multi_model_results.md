# Multi-Model Theological Embeddings — Inter-LLM Variance

## Design

**Models:** `anthropic/claude-sonnet-4`, `openai/gpt-4o`, `google/gemini-2.0-flash-001`, `meta-llama/llama-3.3-70b-instruct`
**Passages:** 23 canonical texts from 10 traditions
**Task:** Score each passage on 12 theological axes (temperature=0)

---

## Inter-Model Agreement

**Mean Pearson correlation (all scores):** 0.8686

### Most Consensual Axes (models agree)

- **transcendence**: CV=0.0998
- **order**: CV=0.1210
- **wisdom**: CV=0.1214
- **authority**: CV=0.1322

### Most Contested Axes (models disagree)

- **war**: CV=0.4628
- **justice**: CV=0.2571
- **death**: CV=0.2361
- **fertility**: CV=0.2350

## Braille Consensus

**Mean bit agreement between models:** 0.8826

---

*Generated by the Multi-Model Theological Embeddings Pipeline — Gods as Centroids*